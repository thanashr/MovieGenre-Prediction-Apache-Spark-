{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import CountVectorizer, StopWordsRemover,Word2Vec\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer,HashingTF,IDF\n",
    "from pyspark.ml.classification import LogisticRegression,LinearSVC\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "localhost\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "java_home = os.environ.get('JAVA_HOME', None)\n",
    "os.environ['SPARK_LOCAL_IP'] = 'localhost'\n",
    "print(java_home)\n",
    "print(os.environ.get('SPARK_LOCAL_IP', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_conf = SparkConf().setAppName(\"test\")\n",
    "# spark = SparkContext(conf = spark_conf)\n",
    "# SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]')\\\n",
    "                        .config(\"spark.driver.memory\",\"15g\")\\\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count=35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")\n",
    "myschema=StructType([StructField(\"movie_id\",StringType(),True)\\\n",
    "                     ,StructField(\"movie_name\",StringType(),True)\\\n",
    "                     ,StructField(\"plot\",StringType(),True)\\\n",
    "                     ,StructField(\"genre\",StringType(),True)\\\n",
    "                    ])\n",
    "spark_df=spark.createDataFrame(df,schema=myschema)\n",
    "df=spark_df\n",
    "mapping_df = spark.read.load(\"mapping.csv\", format='csv', sep=',', inferSchema=True, header=True)\n",
    "for row in mapping_df.rdd.collect():\n",
    "    val=row['0']\n",
    "    def create_cols(row):\n",
    "        if val in row:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    udfconvert=udf(create_cols,IntegerType())\n",
    "    df=df.withColumn(val,udfconvert(\"genre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"plot\", outputCol=\"words\")\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"candidate_words\", pattern=\"\\\\W\")\n",
    "# alternatively, pattern=\"\\\\w+\", gaps(False)\n",
    "\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "\n",
    "regexTokenized = regexTokenizer.transform(df)\n",
    "# regexTokenized.select(\"plot\", \"candidate_\") \\\n",
    "#     .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=True)\n",
    "# remover = StopWordsRemover(inputCol=\"words\", outputCol=\"candidate_words\")\n",
    "filtered_df = regexTokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                plot|     candidate_words|tokens|\n",
      "+--------------------+--------------------+------+\n",
      "|The film is based...|[the, film, is, b...|   786|\n",
      "|A group of teenag...|[a, group, of, te...|    52|\n",
      "|This story of a Z...|[this, story, of,...|   396|\n",
      "|The Stooges play ...|[the, stooges, pl...|   116|\n",
      "|A soldier-of-fort...|[a, soldier, of, ...|    35|\n",
      "|Set in the Northw...|[set, in, the, no...|   407|\n",
      "|Like in many othe...|[like, in, many, ...|   328|\n",
      "|Mickey and the Sc...|[mickey, and, the...|    27|\n",
      "|In the desert wil...|[in, the, desert,...|   396|\n",
      "|Bimbo and Koko ar...|[bimbo, and, koko...|    54|\n",
      "|Tahaan  lives wit...|[tahaan, lives, w...|   372|\n",
      "|Betty is startled...|[betty, is, start...|   167|\n",
      "|Nirmal ([[Karthik...|[nirmal, karthik,...|   180|\n",
      "|A group of journa...|[a, group, of, jo...|   426|\n",
      "|Vaibhavari Sahay,...|[vaibhavari, saha...|   330|\n",
      "|In 1947, the movi...|[in, 1947, the, m...|   391|\n",
      "|Ninja Resurrectio...|[ninja, resurrect...|  2966|\n",
      "|In the spring of ...|[in, the, spring,...|   647|\n",
      "|Muthu ([[Prabhu  ...|[muthu, prabhu, a...|   159|\n",
      "|Vishwanathan , an...|[vishwanathan, an...|   332|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df=pd.read_csv(\"test.csv\")\n",
    "testschema=StructType([StructField(\"movie_id\",StringType(),True)\\\n",
    "                     ,StructField(\"movie_name\",StringType(),True)\\\n",
    "                     ,StructField(\"plot\",StringType(),True)\\\n",
    "                    ])\n",
    "test_spark_df=spark.createDataFrame(test_df,schema=testschema)\n",
    "\n",
    "test_regexTokenized = regexTokenizer.transform(test_spark_df)\n",
    "test_regexTokenized.select(\"plot\", \"candidate_words\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"candidate_words\"))).show(truncate=True)\n",
    "\n",
    "test_filtered_df = test_regexTokenized\n",
    "\n",
    "#test_model = cv.fit(test_filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Part 1 Creating Term-document Matrix ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec=Word2Vec(inputCol=\"candidate_words\",outputCol=\"w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtv_model=word2vec.fit(filtered_df)\n",
    "wtv=wtv_model.transform(filtered_df)\n",
    "\n",
    "test_wtv_model=word2vec.fit(test_filtered_df)\n",
    "test_wtv=test_wtv_model.transform(test_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama\n",
      "Comedy\n",
      "Romance Film\n",
      "Thriller\n",
      "Action\n",
      "World cinema\n",
      "Crime Fiction\n",
      "Horror\n",
      "Black-and-white\n",
      "Indie\n",
      "Action/Adventure\n",
      "Adventure\n",
      "Family Film\n",
      "Short Film\n",
      "Romantic drama\n",
      "Animation\n",
      "Musical\n",
      "Science Fiction\n",
      "Mystery\n",
      "Romantic comedy\n"
     ]
    }
   ],
   "source": [
    "result=wtv\n",
    "test_result=test_wtv\n",
    "log_result=test_result\n",
    "for row in mapping_df.rdd.collect():\n",
    "    val=row['0']\n",
    "    print(val)\n",
    "    lr=LogisticRegression(featuresCol=\"w2v\",labelCol=val,maxIter=800)\n",
    "    lr_model=lr.fit(result)\n",
    "    prediction=lr_model.transform(log_result)\n",
    "    log_result=prediction.withColumnRenamed(\"prediction\",val)\n",
    "    log_result=log_result.drop(*[\"rawPrediction\",\"probability\"])\n",
    "    log_result=log_result.withColumn(val,log_result[val].cast(IntegerType()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_result=log_result.withColumn(\"predictions\",lit(\"\"))\n",
    "for row in mapping_df.rdd.collect():\n",
    "    val=row['0']\n",
    "    log_result=log_result.withColumn(\"predictions\",concat(col(\"predictions\"),lit(\" \"),col(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=log_result.select(\"movie_id\",\"predictions\")\n",
    "out.write.csv(\"sample_w2v.csv\",mode=\"overwrite\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
